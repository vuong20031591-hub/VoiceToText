"""
Voice to Text Application - Main application logic
"""
import json
import logging
import os
import threading
import time
import tempfile
import wave
import queue
from typing import Optional

try:
    import pyaudio
    import numpy as np
    import pyperclip
    import customtkinter as ctk
except ImportError as e:
    print(f"[ERROR] Missing library: {e}")
    import sys
    sys.exit(1)

from ..services import GroqSTTService, VietnameseTextCorrector
from ..gui import ModernVoiceOverlay
from .hotkey_manager import HotkeyManager


class VoiceToTextApp:
    """·ª®ng d·ª•ng Voice to Text ho√†n ch·ªânh trong m·ªôt file"""
    
    def __init__(self):
        """Kh·ªüi t·∫°o ·ª©ng d·ª•ng"""
        self.config = self._load_config()
        self._setup_logging()
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("[START] Initializing Voice to Text Application")
        
        # Audio recording
        self.audio = None
        self.stream = None
        self.is_recording = False
        self.audio_data = []
        self.recording_thread = None
        
        # Speech recognition - Ch·ªâ d√πng Groq STT
        self.remote_stt = None
        
        # Hotkey handling - SIMPLE TOGGLE MODE
        self.record_key = self.config.get('hotkey', {}).get('key', 'f9')
        self.exit_key = self.config.get('hotkey', {}).get('exit_key', 'f10')
        self.hotkey_manager = HotkeyManager(self.record_key, self.exit_key)

        # Exit sequence tracking
        self.exit_sequence = []
        self.exit_sequence_timeout = time.time()
        
        # GUI
        self.gui_enabled = self.config.get('gui', {}).get('show_overlay', True)
        self.root = None
        self.overlay = None
        
        # State
        self.is_running = False
        self.user_stopped_recording = False  # Track if user manually stopped
        self.should_hide_gui = False  # Flag to hide GUI from main thread

        # GUI queue for thread-safe communication
        self.gui_queue = queue.Queue()

        # Audio visualization
        self.current_audio_level = 0
        self.total_audio_energy = 0
        self.audio_samples_count = 0

        # Text correction
        self.text_corrector = None

        # Ch·ªëng d√°n tr√πng l·∫∑p
        self._last_paste_text = ""
        self._last_paste_at = 0.0

        self._initialize()
    
    def _load_config(self) -> dict:
        """T·∫£i c·∫•u h√¨nh"""
        default_config = {
            "stt": {
                "provider": "groq",
                "api_base": "https://api.groq.com/openai/v1",
                "model": "whisper-large-v3",
                "language": "vi",
                "api_key_env": "GROQ_API_KEY",
                "api_key": None,
                "api_keys": [
                    "gsk_xxx",
                    "gsk_xxx",
                    "gsk_xxx",
                    "gsk_xxx",
                    "gsk_xxx"
                ],
                "timeout": 30
            },
            "hotkey": {
                "key": "ctrl+alt",
                "exit_key": "ctrl+shift+c"
            },
            "audio": {
                "sample_rate": 16000,
                "channels": 1,
                "chunk_size": 2048,
                "format": "int16",
                "input_device_index": None,
                "silence_threshold": 150,
                "silence_duration": 3.0,
                "max_recording_time": 30.0,
                "min_recording_time": 1.0,
                "noise_reduction": False,
                "auto_gain": False,
                "voice_activity_detection": False,
                "audio_enhancement": {
                    "enabled": False,
                    "normalize_volume": False,
                    "reduce_noise": False,
                    "enhance_speech": False,
                    "apply_filter": False
                }
            },
            "text_input": {
                "method": "paste",
                "typing_delay": 0.01
            },
            "logging": {
                "level": "WARNING",
                "show_console": False
            },
            "gui": {
                "show_overlay": True,
                "overlay_position": "center",
                "auto_hide_delay": 0.0,
                "theme": "light",
                "window_width": 250,
                "window_height": 150,
                "transparency": 0.95,
                "animation_speed": 0.05,
                "pulse_effect": True,
                "wave_visualization": True
            },
            "text_correction": {
                "enabled": True,
                "method": "dictionary",
                "show_original": False,
                "confidence_threshold": 0.9,
                "fix_tone_marks": True,
                "fix_grammar": False,
                "fix_homophones": False,
                "normalize_text": True,
                "smart_capitalization": False,
                "context_correction": False,
                "vietnamese_specific": {
                    "fix_dialects": False,
                    "standardize_spelling": True,
                    "correct_common_errors": True,
                    "apply_vietnamese_rules": False
                },
                "advanced_features": {
                    "semantic_correction": False,
                    "phrase_level_correction": False,
                    "context_aware_fixes": False
                }
            }
        }
        
        try:
            # T√¨m config.json theo th·ª© t·ª± ∆∞u ti√™n:
            # 1. Working directory (ƒë·ªÉ user c√≥ th·ªÉ override)
            # 2. PyInstaller bundle (embedded trong .exe)
            # 3. Default config (hardcoded)
            
            config_path = None
            
            # Check working directory first
            if os.path.exists("config.json"):
                config_path = "config.json"
                print("[OK] Found config in working directory")
            # Check PyInstaller bundle
            elif getattr(sys, 'frozen', False) and hasattr(sys, '_MEIPASS'):
                bundled_config = os.path.join(sys._MEIPASS, 'config.json')
                if os.path.exists(bundled_config):
                    config_path = bundled_config
                    print("[OK] Found config in PyInstaller bundle")
            
            # Load config if found
            if config_path:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                print(f"[OK] Loaded config from {config_path}")
                # Merge v·ªõi default config
                for key, value in default_config.items():
                    if key not in config:
                        config[key] = value
                return config
                
        except Exception as e:
            print(f"[WARNING] Config load error: {e}")
        
        print("[INFO] Using default config")
        return default_config
    
    def _setup_logging(self):
        """Thi·∫øt l·∫≠p logging"""
        log_config = self.config.get('logging', {})
        log_level = getattr(logging, log_config.get('level', 'INFO').upper())
        
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%H:%M:%S'
        )
        
        # Console handler
        if log_config.get('show_console', True):
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            logging.getLogger().addHandler(console_handler)
        
        # File handler
        file_handler = logging.FileHandler('voice_to_text.log', encoding='utf-8')
        file_handler.setFormatter(formatter)
        logging.getLogger().addHandler(file_handler)
        
        logging.getLogger().setLevel(log_level)
    
    def _initialize(self):
        """Kh·ªüi t·∫°o c√°c th√†nh ph·∫ßn"""
        try:
            print("[CONFIG] Initializing components...")
            
            # Kh·ªüi t·∫°o audio
            print("[AUDIO] Initializing audio...")
            try:
                self.audio = pyaudio.PyAudio()
                print("[OK] Audio initialized")
            except Exception as audio_error:
                print(f"[ERROR] Audio init error: {audio_error}")
                print("[TIP] G·ª£i √Ω gi·∫£i quy·∫øt:")
                print("   1. Ki·ªÉm tra microphone ƒë√£ ƒë∆∞·ª£c k·∫øt n·ªëi")
                print("   2. Ki·ªÉm tra driver audio")
                print("   3. Ch·∫°y ·ª©ng d·ª•ng v·ªõi quy·ªÅn Administrator")
                print("   4. C√†i ƒë·∫∑t l·∫°i: pip install pyaudio")
                self.audio = None
                raise audio_error
            
            # Kh·ªüi t·∫°o Groq STT
            print("[AI] Initializing Groq STT...")
            self._init_groq_stt()
            print("[OK] Groq STT initialized")
            
            # Kh·ªüi t·∫°o GUI n·∫øu c·∫ßn
            if self.gui_enabled:
                print("[GUI] Initializing GUI...")
                self._setup_gui()
                # T·∫°o overlay ngay t·ª´ ƒë·∫ßu
                self._create_modern_overlay()
                print("[OK] GUI initialized")
            
            # Kh·ªüi t·∫°o hotkey listener
            print("[HOTKEY] Initializing hotkey listener...")
            self._setup_hotkey()
            print("[OK] Hotkey listener initialized")

            # Kh·ªüi t·∫°o text corrector
            print("[TEXT] Initializing text corrector...")
            self._setup_text_corrector()
            print("[OK] Text corrector initialized")

            print("[SUCCESS] Initialization complete!")
            self.logger.info("[OK] Kh·ªüi t·∫°o th√†nh c√¥ng")
            
        except Exception as e:
            print(f"[ERROR] Initialization error: {e}")
            self.logger.error(f"[ERROR] Initialization error: {e}")
            raise
    
    def _init_groq_stt(self):
        """Kh·ªüi t·∫°o Groq STT Service"""
        stt_cfg = self.config.get('stt', {})
        
        try:
            api_base = stt_cfg.get('api_base', 'https://api.groq.com/openai/v1')
            model = stt_cfg.get('model', 'whisper-large-v3')
            api_key_env = stt_cfg.get('api_key_env', 'GROQ_API_KEY')
            api_key = stt_cfg.get('api_key', None)
            api_keys = stt_cfg.get('api_keys', None)
            timeout = int(stt_cfg.get('timeout', 60))
            
            self.remote_stt = GroqSTTService(
                api_base=api_base, 
                model=model, 
                api_key_env=api_key_env,
                api_key=api_key,
                api_keys=api_keys,
                timeout=timeout
            )
            
            print(f"[OK] Using Groq Whisper STT: {model}")
            self.logger.info(f"[OK] Using Groq Whisper STT: {model}")
        except Exception as e:
            print(f"[ERROR] Groq STT init error: {e}")
            self.logger.error(f"[ERROR] Groq STT init error: {e}")
            raise
    
    def _setup_gui(self):
        """Thi·∫øt l·∫≠p GUI - KH√îNG C·∫¶N ROOT WINDOW"""
        try:
            print("[RENDER] Setting up GUI...")
            ctk.set_appearance_mode("light")
            ctk.set_default_color_theme("blue")
            
            # KH√îNG T·∫†O ROOT - Overlay s·∫Ω t·ª± t·∫°o CTk window
            self.root = None
            
            self.logger.info("[OK] GUI setup (no root, overlay will create own window)")
        except Exception as e:
            print(f"[WARNING] Cannot setup GUI: {e}")
            self.logger.warning(f"[WARNING] Cannot setup GUI: {e}")
            self.gui_enabled = False
    
    def _setup_hotkey(self):
        """Setup hotkey v·ªõi hold mode"""
        try:
            self.hotkey_manager.register(
                on_start=self._start_hold_recording,
                on_stop=self._stop_hold_recording,
                on_exit=self._on_exit_request
            )
            self.logger.info(f"[READY] Hotkey setup complete")
        except Exception as e:
            self.logger.error(f"[ERROR] Hotkey setup error: {e}")
            raise

    def _setup_text_corrector(self):
        """Thi·∫øt l·∫≠p text corrector"""
        try:
            correction_config = self.config.get('text_correction', {})
            if correction_config.get('enabled', True):
                self.text_corrector = VietnameseTextCorrector(correction_config)
                self.logger.info("[OK] Text corrector ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p")
            else:
                self.logger.info("[WARNING] Text correction b·ªã t·∫Øt")
        except Exception as e:
            self.logger.error(f"[ERROR] L·ªói thi·∫øt l·∫≠p text corrector: {e}")
            self.text_corrector = None
    
    def _start_hold_recording(self):
        """Callback khi B·∫ÆT ƒê·∫¶U gi·ªØ Ctrl+Alt"""
        if self.is_recording:
            return  # Already recording
        
        # Reset flags
        self.user_stopped_recording = False
        self.should_hide_gui = False
        
        # Show GUI
        if self.gui_enabled:
            try:
                self.gui_queue.put(("show_recording",))
            except Exception as e:
                print(f"[ERROR] Error showing GUI: {e}")
        
        # Start recording
        self._start_recording()
    
    def _stop_hold_recording(self):
        """Callback khi TH·∫¢ Ctrl+Alt"""
        print(f"[DEBUG] _stop_hold_recording called, is_recording={self.is_recording}")
        
        # ƒê√°nh d·∫•u user ƒë√£ th·∫£ ph√≠m (kh√¥ng hi·ªÉn th·ªã result GUI)
        self.user_stopped_recording = True
        
        # Set flag ƒë·ªÉ main thread ·∫©n GUI (thread-safe)
        print("[DEBUG] Setting should_hide_gui flag...")
        self.should_hide_gui = True
        
        # Stop recording n·∫øu ƒëang record
        if self.is_recording:
            self._stop_recording()
        else:
            print("[DEBUG] Not recording, skip stop")
    
    def _on_exit_request(self):
        """Exit application"""
        print(f"[STOP] {self.exit_key.upper()} pressed - Exiting...")
        self.is_running = False
        threading.Thread(target=self.stop, daemon=True).start()

    def _process_gui_queue(self):
        """X·ª≠ l√Ω GUI queue trong main thread"""
        try:
            while not self.gui_queue.empty():
                action, *args = self.gui_queue.get_nowait()
                print(f"[DEBUG] Processing GUI queue action: {action}")

                if action == "show_recording":
                    self._show_recording_gui_safe()
                elif action == "hide_gui":
                    print("[DEBUG] Queue action 'hide_gui' received")
                    self._hide_gui_safe()
                elif action == "show_processing":
                    self._show_processing_gui_safe()
                elif action == "show_result":
                    text = args[0] if args else ""
                    self._show_result_gui_safe(text)
                elif action == "show_error":
                    error = args[0] if args else ""
                    self._show_error_gui_safe(error)
                elif action == "update_wave":
                    level = args[0] if args else 0
                    self._update_wave_safe(level)

        except queue.Empty:
            pass
        except Exception as e:
            print(f"[ERROR] GUI queue error: {e}")

    def _show_recording_gui_safe(self):
        """Thread-safe version of show recording GUI"""
        if not self.gui_enabled:
            return
        try:
            if hasattr(self, 'overlay') and self.overlay:
                # L·∫•y quota info hi·ªán t·∫°i
                quota_info = None
                if self.remote_stt:
                    try:
                        quota_info = self.remote_stt.get_quota_info()
                    except:
                        pass
                self.overlay.show_recording_safe(quota_info)
        except Exception as e:
            print(f"[ERROR] GUI error: {e}")

    def _hide_gui_safe(self):
        """Thread-safe version of hide GUI"""
        print("[DEBUG] _hide_gui_safe called")
        if hasattr(self, 'overlay') and self.overlay:
            try:
                print(f"[DEBUG] overlay exists, calling hide_immediately_safe()")
                self.overlay.hide_immediately_safe()
            except Exception as e:
                print(f"[ERROR] GUI hide error: {e}")
        else:
            print(f"[DEBUG] overlay not found: hasattr={hasattr(self, 'overlay')}, overlay={getattr(self, 'overlay', None)}")

    def _show_processing_gui_safe(self):
        """Thread-safe version of show processing GUI"""
        pass  # Implement if needed

    def _show_result_gui_safe(self, text: str):
        """Thread-safe version of show result GUI"""
        pass  # Implement if needed

    def _show_error_gui_safe(self, error: str):
        """Thread-safe version of show error GUI"""
        pass  # Implement if needed

    def _update_wave_safe(self, level: float):
        """Thread-safe version of update wave visualization - C·ª∞C QUAN TR·ªåNG"""
        if hasattr(self, 'overlay') and self.overlay:
            try:
                # Ki·ªÉm tra overlay c√≥ s·∫µn s√†ng kh√¥ng
                if not hasattr(self.overlay, 'is_visible'):
                    return
                
                if not self.overlay.is_visible:
                    return
                
                # C·∫≠p nh·∫≠t wave data - animation loop s·∫Ω t·ª± ƒë·ªông v·∫Ω l·∫°i
                self.overlay.update_wave_data(level)
            except Exception as e:
                # Ch·ªâ in l·ªói quan tr·ªçng
                if "wave" in str(e).lower():
                    print(f"[ERROR] Wave update error: {e}")
    
    def _start_recording(self):
        """B·∫Øt ƒë·∫ßu ghi √¢m"""
        if self.is_recording:
            return

        # Ki·ªÉm tra audio ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o ch∆∞a
        if self.audio is None:
            self.logger.error("[ERROR] Audio ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")
            print("[ERROR] L·ªói: Audio system ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o!")
            print("[TIP] Please kh·ªüi ƒë·ªông l·∫°i ·ª©ng d·ª•ng")
            return

        try:
            audio_config = self.config['audio']

            # L·∫•y input device index t·ª´ config (n·∫øu c√≥)
            input_device_index = audio_config.get('input_device_index', None)
            
            stream_params = {
                'format': pyaudio.paInt16,
                'channels': audio_config['channels'],
                'rate': audio_config['sample_rate'],
                'input': True,
                'frames_per_buffer': audio_config['chunk_size']
            }
            
            # Ch·ªâ ƒë·ªãnh device n·∫øu c√≥ trong config
            if input_device_index is not None:
                stream_params['input_device_index'] = input_device_index
                print(f"[MIC] Using audio device index: {input_device_index}")
            else:
                print("[MIC] Using default audio device")
                print("[TIP] ƒê·ªÉ ch·ªçn thi·∫øt b·ªã c·ª• th·ªÉ, ch·∫°y: python check_audio_devices.py")

            self.stream = self.audio.open(**stream_params)
            print("[DEBUG] Audio stream created successfully")

            self.is_recording = True
            print(f"[DEBUG] is_recording = {self.is_recording}")
            
            self.audio_data = []
            print("[DEBUG] audio_data initialized")

            # Reset audio energy tracking
            self.total_audio_energy = 0
            self.audio_samples_count = 0
            print("[DEBUG] Audio energy tracking reset")

            # B·∫Øt ƒë·∫ßu thread ghi √¢m
            print("[DEBUG] Creating recording thread...")
            self.recording_thread = threading.Thread(target=self._recording_loop)
            self.recording_thread.daemon = True
            print("[DEBUG] Starting recording thread...")
            self.recording_thread.start()
            print("[DEBUG] Recording thread started")

            self.logger.info("[MIC] B·∫Øt ƒë·∫ßu ghi √¢m...")
            print("[MIC] RECORDING... (release hotkey to stop)")
            print("[TIP] Voice Activity Detection:", "B·∫¨T" if audio_config.get('voice_activity_detection', False) else "T·∫ÆT")

        except Exception as e:
            self.logger.error(f"[ERROR] L·ªói b·∫Øt ƒë·∫ßu ghi √¢m: {e}")
            print(f"[ERROR] L·ªói b·∫Øt ƒë·∫ßu ghi √¢m: {e}")
            import traceback
            traceback.print_exc()
            self.is_recording = False
            # ·∫®n GUI n·∫øu c√≥ l·ªói
            if self.gui_enabled:
                self._hide_gui()
    
    def _recording_loop(self):
        """V√≤ng l·∫∑p ghi √¢m"""
        audio_config = self.config['audio']
        silence_start = None
        recording_start = time.time()
        
        while self.is_recording:
            try:
                # Ki·ªÉm tra stream h·ª£p l·ªá
                if not self.stream:
                    self.logger.error("[ERROR] Stream ƒë√£ ƒë∆∞·ª£c ƒë√≥ng ho·∫∑c ch∆∞a kh·ªüi t·∫°o")
                    break
                    
                data = self.stream.read(audio_config['chunk_size'], exception_on_overflow=False)
                self.audio_data.append(data)
                
                # Calculate audio level for visualization
                audio_array = np.frombuffer(data, dtype=np.int16)
                if len(audio_array) > 0:
                    # RMS (Root Mean Square) cho ƒë·ªô ch√≠nh x√°c cao h∆°n
                    volume = np.sqrt(np.mean(audio_array.astype(np.float32)**2))
                    
                    # Normalize volume for visualization (0-1) - TƒÉng sensitivity
                    # S·ª≠ d·ª•ng scale factor th·∫•p h∆°n ƒë·ªÉ wave nh·∫°y h∆°n
                    normalized_volume = min(volume / 500.0, 1.0)  # Gi·∫£m t·ª´ 1000 xu·ªëng 500
                    self.current_audio_level = normalized_volume

                    # Track total audio energy
                    self.total_audio_energy += volume
                    self.audio_samples_count += 1

                    # Send audio level to GUI - QUAN TR·ªåNG cho hi·ªáu ·ª©ng wave
                    if self.gui_enabled:
                        try:
                            self.gui_queue.put(("update_wave", normalized_volume))
                            # Ch·ªâ log khi c√≥ √¢m thanh ƒë√°ng k·ªÉ
                            if normalized_volume > 0.05:
                                print(f"[WAVE] Level: {normalized_volume:.3f}")
                        except Exception as e:
                            print(f"[ERROR] Queue error: {e}")
                else:
                    volume = 0
                    normalized_volume = 0
                    # G·ª≠i level = 0 ƒë·ªÉ wave v·ªÅ 0
                    if self.gui_enabled:
                        try:
                            self.gui_queue.put(("update_wave", 0.0))
                        except:
                            pass

                # Voice activity detection (ch·ªâ khi b·∫≠t)
                if audio_config.get('voice_activity_detection', False):
                    if volume > audio_config['silence_threshold']:
                        silence_start = None
                    else:
                        if silence_start is None:
                            silence_start = time.time()
                        elif time.time() - silence_start > audio_config['silence_duration']:
                            # Ch·ªâ d·ª´ng n·∫øu ƒë√£ ghi ƒë·ªß th·ªùi gian t·ªëi thi·ªÉu
                            if time.time() - recording_start >= audio_config.get('min_recording_time', 1.0):
                                self.logger.info("üîá Ph√°t hi·ªán im l·∫∑ng, d·ª´ng ghi √¢m")
                                break
                
                # Ki·ªÉm tra th·ªùi gian t·ªëi ƒëa
                if time.time() - recording_start > audio_config['max_recording_time']:
                    self.logger.info("‚è∞ ƒê·∫°t th·ªùi gian ghi √¢m t·ªëi ƒëa")
                    break
                    
            except Exception as e:
                self.logger.error(f"[ERROR] L·ªói ghi √¢m: {e}")
                break
        
        # T·ª± ƒë·ªông d·ª´ng
        if self.is_recording:
            self.is_recording = False
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
                self.stream = None
            
            # X·ª≠ l√Ω audio (ch·ªâ khi ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω)
            if self.audio_data:
                audio_bytes = b''.join(self.audio_data)
                self.audio_data = []  # Clear ƒë·ªÉ tr√°nh duplicate
                threading.Thread(target=self._process_audio, args=(audio_bytes,), daemon=True).start()
    
    def _stop_recording(self):
        """Stopping recording"""
        if not self.is_recording:
            return

        self.is_recording = False

        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None

        self.logger.info("[STOP] Stopping recording")
        print("[STOP] Stopping recording - Processing...")

        # X·ª≠ l√Ω audio (l·∫•y v√† clear data ngay ƒë·ªÉ tr√°nh duplicate)
        if self.audio_data:
            audio_bytes = b''.join(self.audio_data)
            self.audio_data = []  # Clear ngay ƒë·ªÉ tr√°nh x·ª≠ l√Ω 2 l·∫ßn!
            threading.Thread(target=self._process_audio, args=(audio_bytes,), daemon=True).start()
    
    def _process_audio(self, audio_data: bytes):
        """X·ª≠ l√Ω audio v√† nh·∫≠n d·∫°ng"""
        try:
            # Ki·ªÉm tra m·ª©c ƒë·ªô √¢m thanh trung b√¨nh
            if self.audio_samples_count > 0:
                avg_audio_energy = self.total_audio_energy / self.audio_samples_count
                min_energy_threshold = 50  # Ng∆∞·ª°ng √¢m thanh t·ªëi thi·ªÉu

                if avg_audio_energy < min_energy_threshold:
                    self.logger.info("üîá √Çm thanh qu√° nh·ªè, b·ªè qua nh·∫≠n d·∫°ng")
                    print("üîá Kh√¥ng ph√°t hi·ªán gi·ªçng n√≥i r√µ r√†ng")
                    # Ensure GUI is hidden
                    if self.gui_enabled:
                        try:
                            self.gui_queue.put(("hide_gui",))
                        except:
                            pass
                    return

                self.logger.info(f"üéµ M·ª©c √¢m thanh trung b√¨nh: {avg_audio_energy:.1f}")

            self.logger.info("[DEBUG] ƒêang nh·∫≠n d·∫°ng gi·ªçng n√≥i...")
            print("[DEBUG] ƒêang nh·∫≠n d·∫°ng gi·ªçng n√≥i...")

            # T·∫°o file t·∫°m
            temp_fd, temp_path = tempfile.mkstemp(suffix='.wav')
            
            try:
                # Chuy·ªÉn ƒë·ªïi v√† x·ª≠ l√Ω audio data
                audio_array = np.frombuffer(audio_data, dtype=np.int16)

                # Ki·ªÉm tra ƒë·ªô d√†i audio t·ªëi thi·ªÉu
                duration_seconds = len(audio_array) / self.config['audio']['sample_rate']
                min_duration = self.config['audio'].get('min_recording_time', 1.0)  # T·ªëi thi·ªÉu 1.0 seconds

                if duration_seconds < min_duration:
                    self.logger.info(f"üîá Audio qu√° ng·∫Øn ({duration_seconds:.2f}s < {min_duration}s), b·ªè qua nh·∫≠n d·∫°ng")
                    print(f"üîá Record qu√° ng·∫Øn ({duration_seconds:.2f}s) - c·∫ßn √≠t nh·∫•t {min_duration}s")
                    print("[TIP] Th·ª≠ n√≥i l√¢u h∆°n ƒë·ªÉ c√≥ k·∫øt qu·∫£ ch√≠nh x√°c h∆°n")
                    # Ensure GUI is hidden
                    if self.gui_enabled:
                        try:
                            self.gui_queue.put(("hide_gui",))
                        except:
                            pass
                    return

                # C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng audio
                audio_array = self._enhance_audio(audio_array)

                with wave.open(temp_path, 'wb') as wav_file:
                    wav_file.setnchannels(1)
                    wav_file.setsampwidth(2)
                    wav_file.setframerate(self.config['audio']['sample_rate'])
                    wav_file.writeframes(audio_array.tobytes())
                
                # Nh·∫≠n d·∫°ng b·∫±ng Groq STT
                try:
                    stt_config = self.config.get('stt', {})
                    language = stt_config.get('language', 'vi')
                    print("[NET] G·ªçi Groq STT...")
                    recognized_text = self.remote_stt.transcribe(temp_path, language=language)
                    
                    # C·∫≠p nh·∫≠t quota info l√™n GUI
                    if self.gui_enabled and self.overlay:
                        try:
                            quota_info = self.remote_stt.get_quota_info()
                            self.root.after(0, lambda: self.overlay.update_quota_info(quota_info))
                        except Exception as e:
                            pass
                            
                except Exception as e:
                    self.logger.error(f"[ERROR] L·ªói Groq STT: {e}")
                    print(f"[ERROR] L·ªói Groq STT: {e}")
                    # Ensure GUI is hidden
                    if self.gui_enabled:
                        try:
                            self.gui_queue.put(("hide_gui",))
                        except:
                            pass
                    return

                # Post-processing cho ti·∫øng Vi·ªát
                recognized_text = self._post_process_vietnamese_text(recognized_text, language)

                if recognized_text and self._is_meaningful_text(recognized_text):
                    self.logger.info(f"[OK] Nh·∫≠n d·∫°ng th√†nh c√¥ng: '{recognized_text}'")
                    print(f"[OK] Result: '{recognized_text}'")
                    print("[TEXT] Pasting text...")

                    if self.gui_enabled and self.root:
                        try:
                            self.root.after(0, lambda: self._show_result_gui(recognized_text))
                        except:
                            pass

                    self._paste_text(recognized_text)
                else:
                    self.logger.warning("[WARNING] Cannot recognize text")
                    print("[WARNING] Cannot recognize text")
                    if self.gui_enabled and self.root:
                        try:
                            self.root.after(0, lambda: self._show_error_gui("Cannot recognize text"))
                        except:
                            pass
                
            finally:
                # X√≥a file t·∫°m
                try:
                    os.close(temp_fd)
                    os.unlink(temp_path)
                except:
                    pass
                    
        except Exception as e:
            error_msg = f"L·ªói nh·∫≠n d·∫°ng: {e}"
            self.logger.error(f"[ERROR] {error_msg}")
            print(f"[ERROR] {error_msg}")
            
            if self.gui_enabled and self.root:
                self.root.after(0, lambda: self._show_error_gui(error_msg))
        
        # Kh√¥ng c·∫ßn ·∫©n GUI ·ªü ƒë√¢y v√¨ ƒë√£ ·∫©n khi th·∫£ hotkey

    def _enhance_audio(self, audio_array: np.ndarray) -> np.ndarray:
        """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng audio cho nh·∫≠n d·∫°ng t·ªët h∆°n v·ªõi c√°c k·ªπ thu·∫≠t n√¢ng cao"""
        try:
            audio_config = self.config['audio'].get('audio_enhancement', {})
            if not audio_config.get('enabled', True):
                return audio_array.astype(np.int16)

            # Chuy·ªÉn ƒë·ªïi sang float32 ƒë·ªÉ x·ª≠ l√Ω ch√≠nh x√°c h∆°n
            if np.max(np.abs(audio_array)) == 0:
                return audio_array.astype(np.int16)
                
            audio_float = audio_array.astype(np.float32)
            
            # 1. Lo·∫°i b·ªè DC offset (d·ªãch chuy·ªÉn DC)
            if audio_config.get('reduce_noise', True):
                audio_float = audio_float - np.mean(audio_float)
            
            # 2. Chu·∫©n h√≥a √¢m l∆∞·ª£ng ban ƒë·∫ßu
            if audio_config.get('normalize_volume', True):
                max_val = np.max(np.abs(audio_float))
                if max_val > 0:
                    audio_float = audio_float / max_val * 0.85  # Gi·ªØ l·∫°i headroom
            
            # 3. L·ªçc th√¥ng cao ƒë·ªÉ lo·∫°i b·ªè ti·∫øng ·ªìn t·∫ßn s·ªë th·∫•p
            if audio_config.get('apply_filter', True) and len(audio_float) > 2:
                # High-pass filter ƒë∆°n gi·∫£n (RC filter)
                alpha = 0.97  # Cut-off frequency kho·∫£ng 50Hz ·ªü 16kHz
                filtered = np.zeros_like(audio_float)
                filtered[0] = audio_float[0]
                for i in range(1, len(audio_float)):
                    filtered[i] = alpha * (filtered[i-1] + audio_float[i] - audio_float[i-1])
                audio_float = filtered
            
            # 4. Gi·∫£m ti·∫øng ·ªìn th√¥ng minh (Spectral Subtraction ƒë∆°n gi·∫£n)
            if audio_config.get('reduce_noise', True) and len(audio_float) > 512:
                # ∆Ø·ªõc l∆∞·ª£ng ti·∫øng ·ªìn t·ª´ 10% ƒë·∫ßu c·ªßa signal
                noise_sample_length = min(len(audio_float) // 10, 1600)  # 0.1s ·ªü 16kHz
                noise_estimate = np.std(audio_float[:noise_sample_length])
                
                # Ch·ªâ √°p d·ª•ng n·∫øu c√≥ ti·∫øng ·ªìn ƒë√°ng k·ªÉ
                if noise_estimate > 0:
                    # Soft thresholding
                    threshold = noise_estimate * 2.0
                    audio_float = np.where(
                        np.abs(audio_float) > threshold,
                        audio_float,
                        audio_float * 0.3  # Gi·∫£m ti·∫øng ·ªìn xu·ªëng 30%
                    )
            
            # 5. T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh khu·∫øch ƒë·∫°i th√¥ng minh
            if audio_config.get('normalize_volume', True):
                # T√≠nh RMS (Root Mean Square) cho m·ª©c √¢m thanh trung b√¨nh
                rms = np.sqrt(np.mean(audio_float**2))
                if rms > 0:
                    # M·ª•c ti√™u RMS t·ªëi ∆∞u cho speech recognition
                    target_rms = 0.25
                    gain = target_rms / rms
                    
                    # Gi·ªõi h·∫°n gain ƒë·ªÉ tr√°nh clip v√† nhi·ªÖu qu√° m·ª©c
                    gain = min(gain, 4.0)  # T·ªëi ƒëa 4x
                    gain = max(gain, 0.1)  # T·ªëi thi·ªÉu 0.1x
                    
                    audio_float = audio_float * gain
            
            # 6. N√©n ƒë·ªông (Dynamic Range Compression) ƒë·ªÉ c√¢n b·∫±ng √¢m thanh
            if audio_config.get('enhance_speech', True):
                # Soft limiter ƒë·ªÉ gi·∫£m dynamic range qu√° l·ªõn
                threshold = 0.8
                ratio = 0.5  # Compression ratio
                
                abs_audio = np.abs(audio_float)
                over_threshold = abs_audio > threshold
                
                if np.any(over_threshold):
                    # √Åp d·ª•ng compression cho c√°c sample v∆∞·ª£t ng∆∞·ª°ng
                    compressed = threshold + (abs_audio - threshold) * ratio
                    audio_float = np.where(
                        over_threshold,
                        np.sign(audio_float) * compressed,
                        audio_float
                    )
            
            # 7. Chu·∫©n h√≥a cu·ªëi c√πng v√† chuy·ªÉn v·ªÅ int16
            # ƒê·∫£m b·∫£o kh√¥ng b·ªã clip
            max_val = np.max(np.abs(audio_float))
            if max_val > 0.95:
                audio_float = audio_float / max_val * 0.95
            
            # Chuy·ªÉn v·ªÅ int16 v·ªõi gi·ªõi h·∫°n ch√≠nh x√°c
            audio_int16 = np.clip(audio_float * 32767, -32768, 32767).astype(np.int16)
            
            # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng k·∫øt qu·∫£
            final_rms = np.sqrt(np.mean((audio_int16.astype(np.float32) / 32767)**2))
            self.logger.debug(f"üéß Audio enhancement: RMS = {final_rms:.3f}, Max = {np.max(np.abs(audio_int16))}")
            
            return audio_int16

        except Exception as e:
            self.logger.warning(f"L·ªói x·ª≠ l√Ω audio n√¢ng cao: {e}")
            # Fallback v·ªÅ normalize ƒë∆°n gi·∫£n
            try:
                if np.max(np.abs(audio_array)) > 0:
                    normalized = audio_array.astype(np.float32)
                    normalized = normalized / np.max(np.abs(normalized)) * 0.8
                    return np.clip(normalized * 32767, -32768, 32767).astype(np.int16)
            except:
                pass
            return audio_array.astype(np.int16)

    def _post_process_vietnamese_text(self, text: str, language: str = "vi") -> str:
        """Post-processing cho vƒÉn b·∫£n ti·∫øng Vi·ªát v·ªõi AI text correction"""
        if not text:
            return text

        try:
            # 1. AI Text Correction (n·∫øu ƒë∆∞·ª£c b·∫≠t)
            if self.text_corrector and language == "vi":
                text = self.text_corrector.correct_text(text, language)

            # 2. Legacy corrections (backup cho c√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát)
            text = self._apply_legacy_corrections(text)

            return text

        except Exception as e:
            self.logger.warning(f"L·ªói post-processing: {e}")
            return text

    def _apply_legacy_corrections(self, text: str) -> str:
        """√Åp d·ª•ng corrections c≈© l√†m backup"""
        try:
            # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
            text = " ".join(text.split())

            # M·ªôt s·ªë corrections ƒë·∫∑c bi·ªát kh√¥ng c√≥ trong dictionary
            special_corrections = {
                "xin k√©o": "xin ch√†o",
                "xin g√†o": "xin ch√†o",
                "xin gao": "xin ch√†o",
                "xin kao": "xin ch√†o",
                "sin ch√†o": "xin ch√†o",
            }

            # Pattern-based corrections cho l·ªói nh·∫≠n d·∫°ng ph·ªï bi·∫øn
            import re

            # S·ª≠a "qu√™ kh√¥ng" th√†nh "kh·ªèe kh√¥ng" trong ng·ªØ c·∫£nh h·ªèi thƒÉm
            text = re.sub(r'\b(b·∫°n|ban)\s+(qu√™|que)\s+(kh√¥ng|khong|ko)\b',
                         r'\1 kh·ªèe kh√¥ng', text, flags=re.IGNORECASE)

            # S·ª≠a "xin ch√†o b·∫°n qu√™ kh√¥ng" th√†nh "xin ch√†o b·∫°n kh·ªèe kh√¥ng"
            text = re.sub(r'\b(xin\s+ch√†o|ch√†o)\s+(b·∫°n|ban)\s+(qu√™|que)\s+(kh√¥ng|khong|ko)\b',
                         r'\1 \2 kh·ªèe kh√¥ng', text, flags=re.IGNORECASE)

            # √Åp d·ª•ng special corrections
            text_lower = text.lower()
            for wrong, correct in special_corrections.items():
                if wrong in text_lower:
                    # Gi·ªØ nguy√™n case c·ªßa t·ª´ ƒë·∫ßu ti√™n
                    if text and text[0].isupper():
                        correct = correct.capitalize()
                    text = text_lower.replace(wrong, correct)
                    break

            return text

        except Exception as e:
            self.logger.warning(f"L·ªói legacy corrections: {e}")
            return text

    def _is_meaningful_text(self, text: str) -> bool:
        """Ki·ªÉm tra vƒÉn b·∫£n c√≥ √Ω nghƒ©a hay kh√¥ng"""
        if not text or len(text.strip()) < 2:
            return False

        text = text.lower().strip()

        # Lo·∫°i b·ªè c√°c vƒÉn b·∫£n kh√¥ng c√≥ √Ω nghƒ©a
        meaningless_patterns = [
            # C√°c t·ª´ l·∫∑p l·∫°i
            r'(.)\1{4,}',  # K√Ω t·ª± l·∫∑p l·∫°i 5 l·∫ßn tr·ªü l√™n
            r'\b(\w+)\s+\1\s+\1\s+\1',  # T·ª´ l·∫∑p l·∫°i 4 l·∫ßn

            # C√°c c·ª•m t·ª´ v√¥ nghƒ©a
            r'^(uh|um|ah|eh|mm|hmm|hm)+\.?$',
            r'^(hello\?|hi\?|hey\?)\.?$',
            r'^(c·∫£m ∆°n .*){3,}',  # "c·∫£m ∆°n" l·∫∑p l·∫°i nhi·ªÅu l·∫ßn
            r'^(k√™nh .*){5,}',    # "k√™nh" l·∫∑p l·∫°i nhi·ªÅu l·∫ßn

            # Ch·ªâ c√≥ d·∫•u c√¢u
            r'^[^\w\s]*$',

            # VƒÉn b·∫£n qu√° ng·∫Øn v√† v√¥ nghƒ©a
            r'^[a-z]\.?$',  # Ch·ªâ m·ªôt ch·ªØ c√°i
        ]

        import re
        for pattern in meaningless_patterns:
            if re.search(pattern, text):
                self.logger.info(f"üîá VƒÉn b·∫£n v√¥ nghƒ©a b·ªã lo·∫°i b·ªè: '{text}'")
                return False

        # Ki·ªÉm tra t·ª∑ l·ªá t·ª´ l·∫∑p l·∫°i
        words = text.split()
        if len(words) > 3:
            unique_words = set(words)
            repetition_ratio = len(words) / len(unique_words)
            if repetition_ratio > 3:  # Qu√° nhi·ªÅu t·ª´ l·∫∑p l·∫°i
                self.logger.info(f"üîá Qu√° nhi·ªÅu t·ª´ l·∫∑p l·∫°i: '{text}'")
                return False

        return True
    
    def _normalize_duplicate_text(self, text: str) -> str:
        """Chu·∫©n ho√° n·∫øu vƒÉn b·∫£n v√¥ t√¨nh b·ªã l·∫∑p 2 l·∫ßn li√™n ti·∫øp"""
        try:
            t = text.strip()
            # Tr∆∞·ªùng h·ª£p ƒë·ªô d√†i g·∫•p ƒë√¥i v√† hai n·ª≠a gi·ªëng nhau (b·ªè kho·∫£ng tr·∫Øng bi√™n)
            if len(t) % 2 == 0:
                half = len(t) // 2
                first = t[:half].strip()
                second = t[half:].strip()
                if first and first == second:
                    return first

            # So s√°nh theo token (b·ªè kho·∫£ng tr·∫Øng)
            tokens = t.split()
            if len(tokens) % 2 == 0 and tokens:
                mid = len(tokens) // 2
                if tokens[:mid] == tokens[mid:]:
                    return " ".join(tokens[:mid])
        except Exception:
            pass
        return text

    def _paste_text(self, text: str):
        """D√°n vƒÉn b·∫£n to ·ª©ng d·ª•ng ƒë√≠ch"""
        try:
            # Debounce tr√°nh d√°n tr√πng trong th·ªùi gian ng·∫Øn
            now = time.time()
            candidate = text.strip()
            if candidate and candidate == self._last_paste_text and (now - self._last_paste_at) < 1.0:
                self.logger.info("‚è© B·ªè qua d√°n tr√πng (debounce)")
                return

            # Chu·∫©n ho√° ch·ªëng l·∫∑p (n·∫øu c√≥)
            text = self._normalize_duplicate_text(text)

            # L∆∞u clipboard c≈©
            try:
                old_clipboard = pyperclip.paste()
            except:
                old_clipboard = ""
            
            # Copy vƒÉn b·∫£n m·ªõi
            pyperclip.copy(text)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 ‚Üí 0.05
            
            # Th·ª≠ paste
            method = self.config['text_input']['method']
            
            if method == 'paste':
                # Th·ª≠ Ctrl+V
                import keyboard as kb
                kb.send('ctrl+v')
                time.sleep(0.1)  # Gi·∫£m t·ª´ 0.3 ‚Üí 0.1
                self.logger.info("[OK] ƒê√£ d√°n vƒÉn b·∫£n b·∫±ng Ctrl+V")
            else:
                # Typing t·ª´ng k√Ω t·ª±
                import keyboard as kb
                kb.write(text)
                time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 ‚Üí 0.05
                self.logger.info("[OK] ƒê√£ g√µ vƒÉn b·∫£n")
            
            print("[OK] Text pasted successfully!")
            print("[READY] Ready for next recording...")
            
            # L∆∞u tr·∫°ng th√°i paste g·∫ßn nh·∫•t
            self._last_paste_text = candidate
            self._last_paste_at = now
            
            # Kh√¥i ph·ª•c clipboard
            try:
                time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 ‚Üí 0.05
                pyperclip.copy(old_clipboard)
            except:
                pass
                
        except Exception as e:
            self.logger.error(f"[ERROR] Text paste error: {e}")
            print(f"[ERROR] Text paste error: {e}")
    
    # GUI Methods - Modern Overlay System
    def _show_recording_gui(self):
        """Hi·ªÉn th·ªã GUI ghi √¢m hi·ªán ƒë·∫°i (deprecated - use queue)"""
        # This method is deprecated, use GUI queue instead
        pass

    def _show_processing_gui(self):
        """Hi·ªÉn th·ªã GUI x·ª≠ l√Ω"""
        if self.gui_enabled and hasattr(self, 'overlay') and self.overlay:
            try:
                self.overlay.show_processing()
            except:
                pass

    def _show_result_gui(self, text: str):
        """Hi·ªÉn th·ªã GUI k·∫øt qu·∫£"""
        # Kh√¥ng hi·ªÉn th·ªã n·∫øu user ƒë√£ th·∫£ hotkey
        if self.user_stopped_recording:
            print("[DEBUG] User stopped recording, skip showing result GUI")
            return
            
        if self.gui_enabled and hasattr(self, 'overlay') and self.overlay:
            try:
                self.overlay.show_result(text)
            except:
                pass

    def _show_error_gui(self, error: str):
        """Hi·ªÉn th·ªã GUI l·ªói"""
        # Kh√¥ng hi·ªÉn th·ªã n·∫øu user ƒë√£ th·∫£ hotkey
        if self.user_stopped_recording:
            print("[DEBUG] User stopped recording, skip showing error GUI")
            return
            
        if self.gui_enabled and hasattr(self, 'overlay') and self.overlay:
            try:
                self.overlay.show_error(error)
            except:
                pass

    def _hide_gui(self):
        """·∫®n GUI ngay l·∫≠p t·ª©c (deprecated - use queue)"""
        # This method is deprecated, use GUI queue instead
        pass

    def _create_modern_overlay(self):
        """T·∫°o overlay hi·ªán ƒë·∫°i - CH·ªà T·∫†O 1 L·∫¶N, KH√îNG C·∫¶N ROOT"""
        try:
            # ƒê·∫£m b·∫£o ch·ªâ t·∫°o 1 overlay duy nh·∫•t
            if self.overlay is not None:
                print("[WARNING] Overlay already exists, skip creating new one")
                return
                
            print("[RENDER] Creating standalone overlay window (no parent)...")
            self.overlay = ModernVoiceOverlay(None, self.config['gui'])
            
            # Set root to overlay window ƒë·ªÉ d√πng cho update
            self.root = self.overlay.window
            
            self.logger.info("[OK] Standalone overlay created")
            print("[OK] 1 standalone overlay window created")
        except Exception as e:
            self.logger.error(f"[ERROR] Failed to create overlay: {e}")
            print(f"[ERROR] Failed to create overlay: {e}")
            self.overlay = None
            self.gui_enabled = False
    
    def start(self):
        """B·∫Øt ƒë·∫ßu ·ª©ng d·ª•ng"""
        try:
            self.is_running = True
            
            # Check if hotkey registered
            if not self.hotkey_manager.is_registered:
                self.logger.error("[ERROR] Hotkey not registered")
                print("[ERROR] Error: Hotkey not registered!")
                return
            
            print(f"[READY] Application ready!")
            print(f"[HOTKEY] HOLD {self.record_key.upper()} to record, RELEASE to stop")
            print(f"[STOP] Press {self.exit_key.upper()} to exit")
            print()
            print("[TIP] USAGE GUIDE:")
            print("   1. Open Notepad and click on it")
            print(f"   2. HOLD {self.record_key.upper()} and speak")
            print("   3. Speak clearly to microphone (Vietnamese)")
            print(f"   4. RELEASE {self.record_key.upper()} to stop and transcribe")
            print("   5. Text will be pasted automatically")
            print()
            print("[READY] TIPS:")
            print("   - Speak clearly, moderate speed")
            print("   - Avoid background noise")
            print("   - Hold at least 2-3 seconds")
            print()
            
            # V√≤ng l·∫∑p ch√≠nh
            while self.is_running:
                try:
                    # X·ª≠ l√Ω GUI queue tr∆∞·ªõc
                    if self.gui_enabled:
                        self._process_gui_queue()
                    
                    # Ki·ªÉm tra flag ƒë·ªÉ ·∫©n GUI
                    if self.should_hide_gui:
                        print("[DEBUG] should_hide_gui flag detected, hiding GUI now...")
                        self.should_hide_gui = False
                        if self.gui_enabled and hasattr(self, 'overlay') and self.overlay:
                            try:
                                self.overlay.is_visible = False
                                self.overlay._stop_animation()
                                if self.overlay.window:
                                    self.overlay.window.withdraw()
                                    print("[OK] GUI hidden from main thread")
                            except Exception as e:
                                print(f"[ERROR] Error hiding GUI from main thread: {e}")

                    # C·∫≠p nh·∫≠t GUI - CH·ªà update overlay, KH√îNG update root
                    if self.gui_enabled and self.overlay and self.overlay.window:
                        try:
                            self.overlay.window.update()
                        except:
                            pass
                    elif self.gui_enabled and self.root:
                        # Fallback: d√πng update_idletasks thay v√¨ update ƒë·ªÉ tr√°nh show root
                        try:
                            self.root.update_idletasks()
                        except:
                            pass
                    time.sleep(0.01)
                except Exception as loop_error:
                    # Log exception ƒë·ªÉ debug
                    print(f"[ERROR] Main loop error: {loop_error}")
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            print("\n[HOTKEY] Received stop signal")
        except Exception as e:
            self.logger.error(f"[ERROR] L·ªói v√≤ng l·∫∑p ch√≠nh: {e}")
        finally:
            self.stop()
    
    def stop(self):
        """D·ª´ng ·ª©ng d·ª•ng"""
        print("[HALT] Stopping application...")
        
        self.is_running = False
        
        # Stopping recording
        if self.is_recording:
            self.is_recording = False
        
        # Unhook hotkeys
        if self.hotkey_manager:
            self.hotkey_manager.unregister()
        
        # D·ªçn d·∫πp audio
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        if self.audio:
            self.audio.terminate()
        
        # D·ªçn d·∫πp GUI
        if hasattr(self, 'overlay') and self.overlay:
            try:
                self.overlay.cleanup()
            except:
                pass

        if self.gui_enabled and self.root:
            try:
                self.root.destroy()
            except:
                pass
        
        print("[OK] Application stopped")
